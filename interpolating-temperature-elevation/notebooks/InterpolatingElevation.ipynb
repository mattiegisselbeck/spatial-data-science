{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Title: Interpolation Methods with ArcPy: Interpolating Elevation\n",
    "\n",
    "Course: GIS 5572: ArcGIS II\n",
    "\n",
    "Author(s): Mattie Gisselbeck\n",
    "\n",
    "Date: 3-25-2023\n",
    "\n",
    "Abstract\n",
    "\n",
    "Previously, we built a pipeline that (1) extracts, transforms, and loads data; (2) performs QAQC operations on the imported data; (3) saves the data to a local geodatabase; and (4) then saves it to a PostgresSQL database hosted on Google Cloud. The objective of this lab was to create interpolated temperature maps for the state of Minnesota and evaluate their accuracy using the ETL and QAQC pipeline. The resulting maps and accuracy assessment will be stored in a local geodatabase and PostgresSQL database. The interpolated maps will be viewable on ArcGIS Online MapViewer via GeoJSON from a Flask API endpoint.\n",
    "\n",
    "https://test11-pmz7lxrsca-uc.a.run.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import requests\n",
    "import os\n",
    "import psycopg2\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(r\"\\\\Mac\\Home\\Documents\\git\")\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Querying Elevation Data from PostgresSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute a Query in PostgresSQl Database and Create a Layer\n",
    "arcpy.management.MakeQueryLayer(\n",
    "    input_database=os.path.join(wksp, \"\"),\n",
    "    out_layer_name=\"elevation\",\n",
    "    query=\"SELECT * FROM elevation;\",\n",
    "    oid_fields=\"pointid\",\n",
    "    shape_type=\"POINT\",\n",
    "    srid=\"4326\",\n",
    "    spatial_reference='GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision',\n",
    "    spatial_properties=\"DEFINE_SPATIAL_PROPERTIES\",\n",
    "    m_values=\"DO_NOT_INCLUDE_M_VALUES\",\n",
    "    z_values=\"DO_NOT_INCLUDE_Z_VALUES\",\n",
    "    extent=\"0 0 0 0\"\n",
    ")\n",
    "\n",
    "# Copy Features from Query Layer (Converts Layer to .shp)\n",
    "arcpy.management.CopyFeatures(\n",
    "    in_features=\"elevation\",\n",
    "    out_feature_class=os.path.join(wksp, \"DEM.shp\"),\n",
    "    config_keyword=\"\",\n",
    "    spatial_grid_1=None,\n",
    "    spatial_grid_2=None,\n",
    "    spatial_grid_3=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. Sampling Elevation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Input .shp Path\n",
    "dem = \"DEM.shp\"\n",
    "\n",
    "# Define Output .shp for DEM and DEM Reference Samples\n",
    "dem_sample = \"DEM_Sample.shp\"\n",
    "dem_reference_sample = \"DEM_ReferenceSample.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set Sample Percentage\n",
    "sample_percentage = 1\n",
    "\n",
    "# Count Number of Features in DEM.shp\n",
    "feature_count = int(arcpy.GetCount_management(dem).getOutput(0))\n",
    "feature_count_reference = int(arcpy.GetCount_management(dem).getOutput(0))\n",
    "\n",
    "# Calculate Number of Features to Sample\n",
    "sample_count = int((sample_percentage / 100) * feature_count)\n",
    "sample_count_reference = int((sample_percentage / 100) * feature_count_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a List of Random Feature ID(s) for Sample\n",
    "id_list = random.sample(range(1, feature_count+1), sample_count)\n",
    "\n",
    "# Generate a List of Random Feature id(s) for Reference Sample\n",
    "id_reference_list = random.sample(range(1, feature_count_reference+1), sample_count_reference)\n",
    "\n",
    "# Convert the Lists to Sets and Find Common Points\n",
    "common_elements = set(id_list) & set(id_reference_list)\n",
    "\n",
    "# Remove common points from reference sample list\n",
    "id_reference_list = [item for item in id_reference_list if item not in common_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the Lists to Comma-Separated Strings\n",
    "id_str = \",\".join(str(x) for x in id_list)\n",
    "id_reference_str = \",\".join(str(x) for x in id_reference_list)\n",
    "\n",
    "# Create a SQL Query to Select Randomly Sampled Features for DEM Sample\n",
    "dem_sample_query = '\"FID\" IN ({})'.format(id_str)\n",
    "\n",
    "# Create a SQL Query to Select Randomly Sampled Features for DEM Reference Sample\n",
    "dem_reference_query = '\"FID\" IN ({})'.format(id_reference_str)\n",
    "\n",
    "# Use Select_analysis Tool to Select Features and Create New .shp Files\n",
    "arcpy.Select_analysis(dem, dem_sample, dem_sample_query)\n",
    "arcpy.Select_analysis(dem, dem_reference_sample, dem_reference_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Interpolating Elevation using ArcPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **IDW()** uses the measured values surrounding the prediction location to predict a value for any unsampled location, based on the assumption that things that are close to one another are more alike than those that are farther apart.\n",
    "* **GlobalPolynomialInterpolation()** fits a smooth surface that is defined by a mathematical function (a polynomial) to the input sample points.\n",
    "* **EmpiricalBayesianKriging()** is an interpolation method that accounts for the error in estimating the underlying semi-variogram through repeated simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, April 11, 2023 10:14:00 AM\",\"Succeeded at Tuesday, April 11, 2023 10:19:44 AM (Elapsed Time: 5 minutes 44 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'DEM_IDW_GeostatisticalLayer'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.ddd.Idw(\n",
    "    in_point_features=elev_sample,\n",
    "    z_field=\"grid_code\",\n",
    "    out_raster=os.path.join(wksp, \"IDW_DEM.tif\"),\n",
    "    cell_size=0.1,\n",
    "    power=2,\n",
    "    search_radius=\"VARIABLE 12\",\n",
    "    in_barrier_polyline_features=None\n",
    ")\n",
    "\n",
    "arcpy.ddd.Kriging(\n",
    "    in_point_features=elev_sample,\n",
    "    z_field=\"grid_code\",\n",
    "    out_surface_raster=os.path.join(wksp, \"Kriging_DEM.tif\"),\n",
    "    semiVariogram_props=\"Spherical 0.021245 # # #\",\n",
    "    cell_size=0.1,\n",
    "    search_radius=\"VARIABLE 12\",\n",
    "    out_variance_prediction_raster=None\n",
    ")\n",
    "\n",
    "arcpy.ga.GlobalPolynomialInterpolation(\n",
    "    in_features=elev_sample,\n",
    "    z_field=\"grid_code\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=os.path.join(wksp, \"GPI_DEM.tif\"),\n",
    "    cell_size=0.1,\n",
    "    power=1,\n",
    "    weight_field=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4. Creating an Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_accuracy_assessment (raster, validation_data):\n",
    "\n",
    "     # Define Output Path and Name of Ground Truth vs. Classified .shp\n",
    "    output_acc = Path(raster).stem + '_PointAccuracy' + '.shp'\n",
    "    acc_table = os.path.join(wksp, output_acc)\n",
    "\n",
    "    # Define Output Path and Name, Saves RMSE for Each Interpolation\n",
    "    output_stat = Path(raster).stem + '_Statistics.dbf'\n",
    "    stat_table = os.path.join(wksp, output_stat)\n",
    "\n",
    "    # Extract Predicted Values and Save to Validation Data\n",
    "    arcpy.sa.ExtractValuesToPoints(\n",
    "        in_point_features=validation_data,\n",
    "        in_raster=raster,\n",
    "        out_point_features=acc_table,\n",
    "        interpolate_values=\"NONE\",\n",
    "        add_attributes=\"ALL\"\n",
    "    )\n",
    "    # Rename Default Fields\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"GrndTruth\",\n",
    "        expression=\"!min_tmpf!\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"Classified\",\n",
    "        expression=\"!RASTERVALU!\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    arcpy.management.DeleteField(\n",
    "        in_table=acc_table,\n",
    "        drop_field=\"min_tmpf;RASTERVALU\",\n",
    "        method=\"DELETE_FIELDS\"\n",
    "    )\n",
    "\n",
    "    # Calculate Squared Error\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"Sq_error\",\n",
    "        expression=\"math.pow(!GrndTruth! - !Classified!, 2)\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "\n",
    "    # Create Statistics Table and Calculate Squared Error Sum\n",
    "    arcpy.analysis.Statistics(\n",
    "        in_table=acc_table,\n",
    "        out_table=stat_table,\n",
    "        statistics_fields=\"Sq_error SUM\",\n",
    "        case_field=None,\n",
    "        concatenation_separator=\"\"\n",
    "    )\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=stat_table,\n",
    "        field=\"RMSE\",\n",
    "        expression=\"math.sqrt(!SUM_Sq_err! / !FREQUENCY!)\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "5. Exploratory Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCR</th>\n",
       "      <th>RANK</th>\n",
       "      <th>INCLUDED</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>ME</th>\n",
       "      <th>ME_STD</th>\n",
       "      <th>RMSE_STD</th>\n",
       "      <th>ASE</th>\n",
       "      <th>MAX_ERROR</th>\n",
       "      <th>PERC_ERROR</th>\n",
       "      <th>CRPS</th>\n",
       "      <th>PERC_90</th>\n",
       "      <th>PERC_95</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Empirical Bayesian Kriging - Advanced</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.224318</td>\n",
       "      <td>-0.014816</td>\n",
       "      <td>-0.046929</td>\n",
       "      <td>0.421152</td>\n",
       "      <td>0.390328</td>\n",
       "      <td>10.419940</td>\n",
       "      <td>99.997268</td>\n",
       "      <td>0.087951</td>\n",
       "      <td>99.838284</td>\n",
       "      <td>99.933204</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Empirical Bayesian Kriging - Default</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.268946</td>\n",
       "      <td>-0.904460</td>\n",
       "      <td>-0.106932</td>\n",
       "      <td>0.144849</td>\n",
       "      <td>8.430596</td>\n",
       "      <td>18.220115</td>\n",
       "      <td>99.984547</td>\n",
       "      <td>1.976801</td>\n",
       "      <td>99.992969</td>\n",
       "      <td>99.996484</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inverse Distance Weighted - Optimized</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9.899689</td>\n",
       "      <td>-0.040151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.500000</td>\n",
       "      <td>99.879441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inverse Distance Weighted - Default</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23.355296</td>\n",
       "      <td>-0.074910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>244.125428</td>\n",
       "      <td>99.715578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Global Polynomial Interpolation – Third order</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>390.482435</td>\n",
       "      <td>-0.026003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3988.855961</td>\n",
       "      <td>95.244693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Global Polynomial Interpolation – Second order</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>420.537546</td>\n",
       "      <td>-0.009746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3408.102384</td>\n",
       "      <td>94.878681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            DESCR  RANK INCLUDED        RMSE   \n",
       "0           Empirical Bayesian Kriging - Advanced     1      Yes    0.224318  \\\n",
       "1            Empirical Bayesian Kriging - Default     2      Yes    1.268946   \n",
       "2           Inverse Distance Weighted - Optimized     3      Yes    9.899689   \n",
       "3             Inverse Distance Weighted - Default     4      Yes   23.355296   \n",
       "4   Global Polynomial Interpolation – Third order     5      Yes  390.482435   \n",
       "5  Global Polynomial Interpolation – Second order     6      Yes  420.537546   \n",
       "\n",
       "         ME    ME_STD  RMSE_STD       ASE    MAX_ERROR  PERC_ERROR      CRPS   \n",
       "0 -0.014816 -0.046929  0.421152  0.390328    10.419940   99.997268  0.087951  \\\n",
       "1 -0.904460 -0.106932  0.144849  8.430596    18.220115   99.984547  1.976801   \n",
       "2 -0.040151  0.000000  0.000000  0.000000   124.500000   99.879441  0.000000   \n",
       "3 -0.074910  0.000000  0.000000  0.000000   244.125428   99.715578  0.000000   \n",
       "4 -0.026003  0.000000  0.000000  0.000000  3988.855961   95.244693  0.000000   \n",
       "5 -0.009746  0.000000  0.000000  0.000000  3408.102384   94.878681  0.000000   \n",
       "\n",
       "     PERC_90    PERC_95 geometry  \n",
       "0  99.838284  99.933204     None  \n",
       "1  99.992969  99.996484     None  \n",
       "2   0.000000   0.000000     None  \n",
       "3   0.000000   0.000000     None  \n",
       "4   0.000000   0.000000     None  \n",
       "5   0.000000   0.000000     None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Exploratory Interpolation\n",
    "arcpy.ga.ExploratoryInterpolation(\n",
    "    in_features = \"DEM_RastertoPoint\",\n",
    "    value_field = \"pointid\",\n",
    "    out_cv_table = r\"\\\\Mac\\Home\\Documents\\ArcGIS\\Projects\\Lab3\\Lab3.gdb\\DEM_ExploratoryInterpolation\",\n",
    "    out_geostat_layer = \"DEM_GeostatisticalLayerHighestRank\",\n",
    "    interp_methods = \"EBK;IDW;GPI\",\n",
    "    comparison_method = \"SINGLE\",\n",
    "    criterion = \"ACCURACY\",\n",
    "    criteria_hierarchy = \"ACCURACY PERCENT #\",\n",
    "    weighted_criteria = \"ACCURACY 1\",\n",
    "    exclusion_criteria = None\n",
    ")\n",
    "\n",
    "# Export Table as .dbf\n",
    "arcpy.conversion.ExportTable(\n",
    "    in_table = \"DEM_ExploratoryInterpolation\",\n",
    "    out_table = r\"\\\\Mac\\Home\\Desktop\\DEM_ExpolatoryInterpolation.dbf\",\n",
    "    where_clause = \"\",\n",
    "    use_field_alias_as_name = \"NOT_USE_ALIAS\",\n",
    "    field_mapping = 'DESCR \"Model Description\" true true true 255 Text 0 0,First,#,DEM_ExploratoryInterpolation,DESCR,0,255;RANK \"Rank\" true true true 4 Long 0 0,First,#,DEM_ExploratoryInterpolation,RANK,-1,-1;INCLUDED \"Included\" true true true 255 Text 0 0,First,#,DEM_ExploratoryInterpolation,INCLUDED,0,255;RMSE \"Root Mean Square Error\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,RMSE,-1,-1;ME \"Mean Error\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,ME,-1,-1;ME_STD \"Mean Standardized Error\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,ME_STD,-1,-1;RMSE_STD \"Root Mean Square Standardized Error\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,RMSE_STD,-1,-1;ASE \"Average Standard Error\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,ASE,-1,-1;MAX_ERROR \"Maximum Absolute Error\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,MAX_ERROR,-1,-1;PERC_ERROR \"Percent Error Reduction\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,PERC_ERROR,-1,-1;CRPS \"Average CRPS\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,CRPS,-1,-1;PERC_90 \"Inside 90 Percent Interval\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,PERC_90,-1,-1;PERC_95 \"Inside 95 Percent Interval\" true true true 8 Double 0 0,First,#,DEM_ExploratoryInterpolation,PERC_95,-1,-1',\n",
    "    sort_field = None\n",
    ")\n",
    "\n",
    "# Read .dbf File\n",
    "expolatory_interpolation = r\"/Users/mattiegisselbeck/Desktop/DEM_ExpolatoryInterpolation.dbf\"\n",
    "df = gpd.read_file(expolatory_interpolation)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Lists with File Names With and Without .tif Extension\n",
    "interpolations = ['DEM_IDW.tif', 'DEM_EBK.tif', 'DEM_GPI.tif']\n",
    "interpolators  = ['DEM_IDW', 'DEM_EBK', 'DEM_GPI']\n",
    "\n",
    "# Create Accuracy Assessments for Each Interpolation\n",
    "for i in range(len(interpolations)):\n",
    "    accuracy_assessment(interpolations[i], dem)\n",
    "\n",
    "# Merge Accuracy Assessments\n",
    "arcpy.management.Merge(\n",
    "    inputs=\"AAT_IDW_DEM;AAT_Kriging_DEM;AAT_GPI_DEM_stat\",\n",
    "    output=\"DEM_AccuracyAssessmentTable.dbf\",\n",
    "    field_mappings='Interpolat \"Interpolat\" true true false 255 Text 0 0,First,#;FREQUENCY \"FREQUENCY\" true true false 10 Long 0 10,First,#,Acc_IDW_stat,FREQUENCY,-1,-1,Acc_Kriging_stat,FREQUENCY,-1,-1,Acc_GPI_stat,FREQUENCY,-1,-1;SUM_Sq_err \"SUM_Sq_err\" true true false 19 Double 0 0,First,#,Acc_IDW_stat,SUM_Sq_err,-1,-1,Acc_Kriging_stat,SUM_Sq_err,-1,-1,Acc_GPI_stat,SUM_Sq_err,-1,-1;RMSE \"RMSE\" true true false 13 Float 0 0,First,#,Acc_IDW_stat,RMSE,-1,-1,Acc_Kriging_stat,RMSE,-1,-1,Acc_GPI_stat,RMSE,-1,-1',\n",
    "    add_source=\"NO_SOURCE_INFO\"\n",
    ")\n",
    "\n",
    "# Add Name of Each Interpolator to Merged Table\n",
    "with arcpy.da.UpdateCursor(\"DEM_AccuracyAssessmentTable.dbf\", ['Interpolat']) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i < len(interpolators):\n",
    "            row[0] = interpolators[i]\n",
    "        else:\n",
    "            break\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# Delete Cursor to Release Locks on Data\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find Interpolator with the Lowest Root Mean Square Error (RMSE)\n",
    "methods = {}\n",
    "fields = [\"pointid\", \"RMSE\"]\n",
    "with arcpy.da.SearchCursor('DEM_AccuracyAssessmentTable.dbf', fields) as cursor:\n",
    "    for row in cursor:\n",
    "        methods[row[0]] = row[1]\n",
    "\n",
    "best_interpolator = min(methods, key=methods.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clip to Minnesota State Boundary\n",
    "output_clip = os.path.join(wksp, best_interpolator + '_Minnesota.tif')\n",
    "out_raster = arcpy.sa.ExtractByMask(\n",
    "    in_raster=best_interpolator+'.tif',\n",
    "    in_mask_data=\"Minnesota_StateBoundary.shp\",\n",
    "    extraction_area=\"INSIDE\",\n",
    "    analysis_extent='-97.239102895829 43.499445217943 -89.6516983029999 49.0583312990001 GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]'\n",
    ")\n",
    "out_raster.save(output_clip)\n",
    "\n",
    "# Convert Raster to Point Shapefile\n",
    "output_point_shp = os.path.join(wksp, best_interpolator + '.shp')\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=output_clip,\n",
    "    out_point_features=output_point_shp,\n",
    "    raster_field=\"Value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "6. Saving Layer(s) and Table(s) to PostgresSQL Database Using psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Establish Connection to PostgreSQL Database\n",
    "connection = psycopg2.connect(\n",
    "    host = '34.133.121.12',\n",
    "    port = '5432',\n",
    "    database = 'lab3',\n",
    "    user = 'postgres',\n",
    "    password = 'student',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "6.1. Interpolation: DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Variables\n",
    "point_table = best_interpolator.lower()\n",
    "fields = [\"pointid\", \"grid_code\", \"Shape@WKT\"]\n",
    "\n",
    "# Create Table with Best Interpolator\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {point_table}\")\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE {point_table} (\n",
    "        pointid INT,\n",
    "        grid_code DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT AddGeometryColumn('{point_table}', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate Table\n",
    "with arcpy.da.SearchCursor(output_point_shp, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[2]\n",
    "        cursor.execute(f\"INSERT INTO {point_table} (pointid, grid_code, geom) VALUES (%s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "6.2. Point Accuracy Assessment Table: DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Path of .dbf and Fields\n",
    "accuracy_assessment = 'DEM_AccuracyAssessmentTable.dbf'\n",
    "fields = [\"OID\", \"Interpolat\", \"FREQUENCY\", \"SUM_Sq_err\", \"RMSE\"]\n",
    "\n",
    "# Create Table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS dem_accuracyassessment\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE dem_accuracyassessment (\n",
    "        OID INT,\n",
    "        Interpolat VARCHAR,\n",
    "        FREQUENCY INT,\n",
    "        SUM_Sq_err DOUBLE PRECISION,\n",
    "        RMSE DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "# Populate Table\n",
    "with arcpy.da.SearchCursor(accuracy_assessment, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        cursor.execute(\"INSERT INTO dem_accuracyassessment (OID, Interpolat, FREQUENCY, SUM_Sq_err, RMSE) VALUES (%s, %s, %s, %s, %s)\", (row[0], row[1], row[2], row[3], row[4]))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "6.3. Point Accuracy Assessment Layer: DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Path of .shp\n",
    "data = os.path.join(wksp, 'Acc_' + best_interpolator + '.shp')\n",
    "\n",
    "# Create Table Name\n",
    "table_name = best_interpolator.lower() + '_error_estimation'\n",
    "\n",
    "fields = [\"GrndTruth\", \"Classified\", \"Sq_error\", \"Shape@WKT\"]\n",
    "\n",
    "# Create Ttable\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE {table_name} (\n",
    "        GrndTruth DOUBLE PRECISION,\n",
    "        Classified DOUBLE PRECISION,\n",
    "        Sq_error DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT AddGeometryColumn('{table_name}', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate Table\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[3]\n",
    "        cursor.execute(f\"INSERT INTO {table_name} (GrndTruth, Classified, Sq_error, geom) VALUES (%s, %s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], wkt))\n",
    "\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
