{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Title: Interpolation Methods with ArcPy: Interpolating Temperature\n",
    "\n",
    "Course: GIS 5572: ArcGIS II\n",
    "\n",
    "Author(s): Mattie Gisselbeck\n",
    "\n",
    "Date: 3-25-2023\n",
    "\n",
    "Abstract\n",
    "\n",
    "Previously, we built a pipeline that (1) extracts, transforms, and loads data; (2) performs QAQC operations on the imported data; (3) saves the data to a local geodatabase; and (4) then saves it to a PostgresSQL database hosted on Google Cloud. The objective of this lab was to create interpolated temperature maps for the state of Minnesota and evaluate their accuracy using the ETL and QAQC pipeline. The resulting maps and accuracy assessment will be stored in a local geodatabase and PostgresSQL database. The interpolated maps will be viewable on ArcGIS Online MapViewer via GeoJSON from a Flask API endpoint.\n",
    "\n",
    "https://test11-pmz7lxrsca-uc.a.run.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import requests\n",
    "import os\n",
    "import psycopg2\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"\\\\Mac\\Home\\Documents\\git\")\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1. Querying Temperature Data from PostgresSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve temperature data from PostGIS database\n",
    "arcpy.management.MakeQueryLayer(\n",
    "    input_database=os.path.join(wksp, \"\"),\n",
    "    out_layer_name=\"rwis_stations\",\n",
    "    query=\"SELECT id, min_tmpf, geom FROM stations WHERE date = '2023-03'\",\n",
    "    oid_fields=\"id\",\n",
    "    shape_type=\"POINT\",\n",
    "    srid=\"4326\",\n",
    "    spatial_reference='GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;0 1;0 1;8.98315284119521E-09;2;2;IsHighPrecision',\n",
    "    spatial_properties=\"DO_NOT_DEFINE_SPATIAL_PROPERTIES\",\n",
    "    m_values=\"DO_NOT_INCLUDE_M_VALUES\",\n",
    "    z_values=\"DO_NOT_INCLUDE_Z_VALUES\",\n",
    "    extent='-98.0690216979786 43.2052294998382 -88.6618510633838 49.6779752981444 GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Saturday, April 15, 2023 6:53:34 PM\",\"Succeeded at Saturday, April 15, 2023 6:53:38 PM (Elapsed Time: 3.18 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '\\\\\\\\Mac\\\\Home\\\\Documents\\\\git\\\\temperature.shp'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the temperature as a shapefile in the workspace\n",
    "arcpy.management.CopyFeatures(\n",
    "    in_features=\"rwis_stations\",\n",
    "    out_feature_class=os.path.join(wksp, \"temperature.shp\"),\n",
    "    config_keyword=\"\",\n",
    "    spatial_grid_1=None,\n",
    "    spatial_grid_2=None,\n",
    "    spatial_grid_3=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2. Sampling Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Input Temperature .shp File Path, and Output Training and Validation .shp File Paths\n",
    "input_shapefile = \"temperature.shp\"\n",
    "training_shapefile = os.path.join(wksp, \"training_shapefile.shp\")\n",
    "validation_shapefile = os.path.join(wksp, \"validation_shapefile.shp\")\n",
    "\n",
    "# Set Training Percentage\n",
    "training_percent = 70\n",
    "\n",
    "# Generate a List of ObjectID(s) for Features in 'input_shapefile'\n",
    "all_ids = [row[0] for row in arcpy.da.SearchCursor(input_shapefile, [\"OID@\"])]\n",
    "\n",
    "# Calculate the Number of Features to Use for Training\n",
    "num_training = int((len(all_ids) * training_percent) / 100)\n",
    "\n",
    "# Randomly Select the ObjectID(s) for the Training Features\n",
    "training_ids = random.sample(all_ids, num_training)\n",
    "\n",
    "# Create Lists of ObjectID(s) for the Validation and Training Features\n",
    "validation_ids = [id for id in all_ids if id not in training_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Saturday, April 15, 2023 6:54:52 PM\",\"Succeeded at Saturday, April 15, 2023 6:54:54 PM (Elapsed Time: 1.65 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '\\\\\\\\Mac\\\\Home\\\\Documents\\\\git\\\\validation_shapefile.shp'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create New .shp Files Using Selected ObjectID(s) for Training and Validation\n",
    "training = arcpy.management.SelectLayerByAttribute(input_shapefile, \"NEW_SELECTION\", \"FID IN {}\".format(tuple(training_ids)))\n",
    "arcpy.management.CopyFeatures(training, training_shapefile)\n",
    "\n",
    "validation = arcpy.management.SelectLayerByAttribute(input_shapefile, \"NEW_SELECTION\", \"FID IN {}\".format(tuple(validation_ids)))\n",
    "arcpy.management.CopyFeatures(validation, validation_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3. Interpolating Temperature using ArcPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "* **IDW()** uses the measured values surrounding the prediction location to predict a value for any unsampled location, based on the assumption that things that are close to one another are more alike than those that are farther apart.\n",
    "* **GlobalPolynomialInterpolation()** fits a smooth surface that is defined by a mathematical function (a polynomial) to the input sample points.\n",
    "* **EmpiricalBayesianKriging()** is an interpolation method that accounts for the error in estimating the underlying semi-variogram through repeated simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Saturday, April 15, 2023 7:01:56 PM\",\"Succeeded at Saturday, April 15, 2023 7:01:57 PM (Elapsed Time: 0.96 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result ''>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.ddd.Idw(\n",
    "    in_point_features=\"training_shapefile.shp\",\n",
    "    z_field=\"min_tmpf\",\n",
    "    out_raster=os.path.join(wksp, \"TMP_IDW.tif\"),\n",
    "    cell_size=0.1,\n",
    "    power=2,\n",
    "    search_radius=\"VARIABLE 12\",\n",
    "    in_barrier_polyline_features=None\n",
    ")\n",
    "\n",
    "arcpy.ga.EmpiricalBayesianKriging(\n",
    "    in_features=\"training_shapefile\",\n",
    "    z_field=\"min_tmpf\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=os.path.join(wksp, \"TMP_EBK.tif\"),\n",
    "    cell_size=0.1,\n",
    "    transformation_type=\"NONE\",\n",
    "    max_local_points=100,\n",
    "    overlap_factor=1,\n",
    "    number_semivariograms=100,\n",
    "    search_neighborhood=\"NBRTYPE=StandardCircular RADIUS=2.3 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\",\n",
    "    output_type=\"PREDICTION\",\n",
    "    quantile_value=0.5,\n",
    "    threshold_type=\"EXCEED\",\n",
    "    probability_threshold=None,\n",
    "    semivariogram_model_type=\"POWER\"\n",
    ")\n",
    "\n",
    "arcpy.ga.GlobalPolynomialInterpolation(\n",
    "    in_features=\"training_shapefile.shp\",\n",
    "    z_field=\"min_tmpf\",\n",
    "    out_ga_layer=None,\n",
    "    out_raster=os.path.join(wksp, \"TMP_GPI.tif\"),\n",
    "    cell_size=0.1,\n",
    "    power=1,\n",
    "    weight_field=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "4. Creating a Point Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy_assessment (raster, validation_data):\n",
    "\n",
    "    # Define Output Path and Name of Ground Truth vs. Classified .shp\n",
    "    output_acc = Path(raster).stem + '_PointAccuracy' + '.shp'\n",
    "    acc_table = os.path.join(wksp, output_acc)\n",
    "    \n",
    "    # Define Output Path and Name, Saves RMSE for Each Interpolation\n",
    "    output_stat = Path(raster).stem + '_Statistics.dbf'\n",
    "    stat_table = os.path.join(wksp, output_stat)\n",
    "    \n",
    "    # Extract Predicted Values and Save to Validation Data\n",
    "    arcpy.sa.ExtractValuesToPoints(\n",
    "        in_point_features=validation_data,\n",
    "        in_raster=raster,\n",
    "        out_point_features=acc_table,\n",
    "        interpolate_values=\"NONE\",\n",
    "        add_attributes=\"ALL\"\n",
    "    )\n",
    "    # Rename Default Fields\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"GrndTruth\",\n",
    "        expression=\"!min_tmpf!\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"Classified\",\n",
    "        expression=\"!RASTERVALU!\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    arcpy.management.DeleteField(\n",
    "        in_table=acc_table,\n",
    "        drop_field=\"min_tmpf;RASTERVALU\",\n",
    "        method=\"DELETE_FIELDS\"\n",
    "    )\n",
    "    \n",
    "    # Calculate Squared Error\n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=acc_table,\n",
    "        field=\"Sq_error\",\n",
    "        expression=\"math.pow(!GrndTruth! - !Classified!, 2)\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )\n",
    "    \n",
    "    # Create Statistics Table and Calculate Squared Error Sum\n",
    "    arcpy.analysis.Statistics(\n",
    "        in_table=acc_table,\n",
    "        out_table=stat_table,\n",
    "        statistics_fields=\"Sq_error SUM\",\n",
    "        case_field=None,\n",
    "        concatenation_separator=\"\"\n",
    "    )    \n",
    "    arcpy.management.CalculateField(\n",
    "        in_table=stat_table,\n",
    "        field=\"RMSE\",\n",
    "        expression=\"math.sqrt(!SUM_Sq_err! / !FREQUENCY!)\",\n",
    "        expression_type=\"PYTHON3\",\n",
    "        code_block=\"\",\n",
    "        field_type=\"FLOAT\",\n",
    "        enforce_domains=\"NO_ENFORCE_DOMAINS\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lists with File Names With and Without .tif Extension\n",
    "interpolations = ['TMP_IDW.tif', 'TMP_EBK.tif', 'TMP_GPI.tif']\n",
    "interpolators  = ['TMP_IDW', 'TMP_EBK', 'TMP_GPI']\n",
    "\n",
    "# Run the accuracy assesment for each interpolation\n",
    "for i in range(len(interpolations)):\n",
    "    accuracy_assessment(interpolations[i], \"validation_shapefile.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists with the raster names of the interpolations with and without extension\n",
    "interpolations = ['TMP_IDW.tif', 'TMP_EBK.tif', 'TMP_GPI.tif']\n",
    "interpolators  = ['TMP_IDW', 'TMP_EBK', 'TMP_GPI']\n",
    "\n",
    "# Merge Accuracy Assessments for Each Interpolations\n",
    "for i in range(len(interpolations)):\n",
    "    accuracy_assessment(interpolations[i], \"validation_shapefile.shp\")\n",
    "\n",
    "# Merge the accuracy tables     \n",
    "arcpy.management.Merge(\n",
    "    inputs=\"TMP_IDW_Statistics.dbf;TMP_EBK_Statistics.dbf;TMP_GPI_Statistics.dbf\",\n",
    "    output=\"TMP_AccuracyAssessment.dbf\",\n",
    "    field_mappings='Interpolat \"Interpolat\" true true false 255 Text 0 0,First,#;FREQUENCY \"FREQUENCY\" true true false 10 Long 0 10,First,#,Acc_IDW_stat,FREQUENCY,-1,-1,Acc_Kriging_stat,FREQUENCY,-1,-1,Acc_GPI_stat,FREQUENCY,-1,-1;SUM_Sq_err \"SUM_Sq_err\" true true false 19 Double 0 0,First,#,Acc_IDW_stat,SUM_Sq_err,-1,-1,Acc_Kriging_stat,SUM_Sq_err,-1,-1,Acc_GPI_stat,SUM_Sq_err,-1,-1;RMSE \"RMSE\" true true false 13 Float 0 0,First,#,Acc_IDW_stat,RMSE,-1,-1,Acc_Kriging_stat,RMSE,-1,-1,Acc_GPI_stat,RMSE,-1,-1',\n",
    "    add_source=\"NO_SOURCE_INFO\"\n",
    ")\n",
    "\n",
    "# Add Name of Each Interpolator to Merged Table\n",
    "with arcpy.da.UpdateCursor(\"TMP_AccuracyAssessment.dbf\", ['Interpolat']) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        if i < len(interpolators):\n",
    "            row[0] = interpolators[i]\n",
    "        else:\n",
    "            break\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# Delete Cursor to Release Locks on Data\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Interpolator with the Lowest Root Mean Square Error (RMSE)\n",
    "methods = {}\n",
    "fields = [\"Interpolat\", \"RMSE\"]\n",
    "with arcpy.da.SearchCursor('TMP_AccuracyAssessment.dbf', fields) as cursor:\n",
    "    for row in cursor:\n",
    "        methods[row[0]] = row[1]\n",
    "\n",
    "best_interpolator = min(methods, key=methods.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Saturday, April 15, 2023 7:16:06 PM\",\"Succeeded at Saturday, April 15, 2023 7:16:08 PM (Elapsed Time: 1.97 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '\\\\\\\\Mac\\\\Home\\\\Documents\\\\git\\\\TMP_EBK.shp'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clip to Minnesota State Boundary\n",
    "output_clip = os.path.join(wksp, best_interpolator + '_Minnesota.tif')\n",
    "out_raster = arcpy.sa.ExtractByMask(\n",
    "    in_raster=best_interpolator+'.tif',\n",
    "    in_mask_data=\"Minnesota_StateBoundary.shp\",\n",
    "    extraction_area=\"INSIDE\",\n",
    "    analysis_extent='-97.239102895829 43.499445217943 -89.6516983029999 49.0583312990001 GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]'\n",
    ")\n",
    "out_raster.save(output_clip)\n",
    "\n",
    "# Convert Raster to Point Shapefile\n",
    "output_point_shp = os.path.join(wksp, best_interpolator + '.shp')\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=output_clip,\n",
    "    out_point_features=output_point_shp,\n",
    "    raster_field=\"Value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "6. Saving Layer(s) and Table(s) to PostgresSQL Database Using psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Connection to PostgreSQL Database\n",
    "connection = psycopg2.connect(\n",
    "    host = '34.133.121.12',\n",
    "    port = '5432',\n",
    "    database = 'lab3',\n",
    "    user = 'postgres',\n",
    "    password = 'student',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "6.1. Interpolation: Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define .dbf Path\n",
    "data = os.path.join('TMP_AccuracyAssessment.dbf')\n",
    "\n",
    "# Define Fields\n",
    "fields = [\"OID\", \"Interpolat\", \"FREQUENCY\", \"SUM_Sq_err\", \"RMSE\"]\n",
    "\n",
    "# Create Table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS TMP_PointAccuracyAssessmentTable\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE TMP_PointAccuracyAssessmentTable (\n",
    "        OID INT,\n",
    "        Interpolat VARCHAR,\n",
    "        FREQUENCY INT,\n",
    "        SUM_Sq_err DOUBLE PRECISION,\n",
    "        RMSE DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "# Populate Table\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        cursor.execute(\"INSERT INTO TMP_PointAccuracyAssessmentTable (OID, Interpolat, FREQUENCY, SUM_Sq_err, RMSE) VALUES (%s, %s, %s, %s, %s)\", (row[0], row[1], row[2], row[3], row[4]))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "6.2. Point Accuracy Assessment Table: Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Table Name (Best Interpolator)\n",
    "point_table = best_interpolator.lower()\n",
    "\n",
    "# Define Fields\n",
    "fields = [\"pointid\", \"grid_code\", \"Shape@WKT\"]\n",
    "\n",
    "# Create Table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {point_table}\")\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE {point_table} (\n",
    "        pointid INT,\n",
    "        grid_code DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT AddGeometryColumn('{point_table}', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate Table\n",
    "with arcpy.da.SearchCursor(output_point_shp, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[2]\n",
    "        cursor.execute(f\"INSERT INTO {point_table} (pointid, grid_code, geom) VALUES (%s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "6.3. Point Accuracy Assessment Layer: Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define .shp Path\n",
    "data = os.path.join(wksp, 'Acc_' + best_interpolator + '.shp')\n",
    "\n",
    "# Define Table Name (i.e., DEM_EBK_PointAccuracy)\n",
    "table_name = best_interpolator.lower() + '_PointAccuracy'\n",
    "\n",
    "# Define Fields\n",
    "fields = [\"GrndTruth\", \"Classified\", \"Sq_error\", \"Shape@WKT\"]\n",
    "\n",
    "# Create Table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "cursor.execute(f\"\"\"\n",
    "    CREATE TABLE {table_name} (\n",
    "        GrndTruth DOUBLE PRECISION,\n",
    "        Classified DOUBLE PRECISION,\n",
    "        Sq_error DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(f\"\"\"\n",
    "    SELECT AddGeometryColumn('{table_name}', 'geom', 4326, 'POINT', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate Table\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[3]\n",
    "        cursor.execute(f\"INSERT INTO {table_name} (GrndTruth, Classified, Sq_error, geom) VALUES (%s, %s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], wkt))\n",
    "\n",
    "connection.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
